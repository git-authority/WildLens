{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "958234d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files from C:\\Users\\Sreeja Mondal\\Downloads\\archive (25).zip extracted to animal_dataset\n",
      "Files from C:\\Users\\Sreeja Mondal\\Downloads\\archive (26).zip extracted to animal_dataset\n",
      "Number of files extracted: 4\n",
      "First 10 files: ['animals', 'images_and_urls', 'name of the animals.txt', 'urls']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_paths = [\n",
    "    r\"C:\\Users\\Sreeja Mondal\\Downloads\\archive (25).zip\",\n",
    "    r\"C:\\Users\\Sreeja Mondal\\Downloads\\archive (26).zip\"\n",
    "]\n",
    "\n",
    "extract_dir = 'animal_dataset'\n",
    "\n",
    "if not os.path.exists(extract_dir):\n",
    "    os.makedirs(extract_dir)\n",
    "\n",
    "for uploaded_zip_path in zip_paths:\n",
    "    with zipfile.ZipFile(uploaded_zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f'Files from {uploaded_zip_path} extracted to {extract_dir}')\n",
    "\n",
    "extracted_files = os.listdir(extract_dir)\n",
    "print(f'Number of files extracted: {len(extracted_files)}')\n",
    "print(f'First 10 files: {extracted_files[:10]}')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91554c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1797ab23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f382af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of animal_dataset/animals/combined_file: ['antelope', 'badger', 'bald_eagle', 'bat', 'bear', 'bee', 'beetle', 'bighorn_sheep', 'bison', 'black_bear', 'boar', 'burrowing_owl', 'butterfly', 'canada_goose_bird', 'caribou', 'cat', 'caterpillar', 'chimpanzee', 'cockroach', 'cougar', 'cow', 'coyote', 'crab', 'crow', 'deer', 'dog', 'dolphin', 'donkey', 'dragonfly', 'duck', 'eagle', 'elephant', 'elk', 'flamingo', 'fly', 'fox', 'goat', 'golden_eagle', 'goldfish', 'goose', 'gorilla', 'grasshopper', 'great_horned_owl', 'grizzly_bear', 'hamster', 'hare', 'hedgehog', 'hippopotamus', 'hornbill', 'horse', 'hummingbird', 'hyena', 'jellyfish', 'kangaroo', 'koala', 'ladybugs', 'leopard', 'lion', 'lizard', 'lobster', 'lynx', 'moose', 'mosquito', 'moth', 'mountain_goat', 'mouse', 'mule_deer', 'octopus', 'okapi', 'orangutan', 'otter', 'owl', 'ox', 'oyster', 'panda', 'parrot', 'pelecaniformes', 'penguin', 'pig', 'pigeon', 'pine_marten', 'porcupine', 'possum', 'raccoon', 'rat', 'reindeer', 'rhinoceros', 'river_otter', 'sandpiper', 'seahorse', 'seal', 'shark', 'sheep', 'snake', 'snow_goose', 'sparrow', 'squid', 'squirrel', 'starfish', 'swan', 'tiger', 'turkey', 'turtle', 'whale', 'white_tail_deer', 'wolf', 'wombat', 'woodpecker', 'zebra']\n"
     ]
    }
   ],
   "source": [
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb49177f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files in animal_dataset/animals/combined_file: 7484\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_files_in_directory(directory):\n",
    "    file_count = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        file_count += len(files)\n",
    "    return file_count\n",
    "\n",
    "file_count = count_files_in_directory(output_dir)\n",
    "print(f\"Total number of files in {output_dir}: {file_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eac23ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,BatchNormalization,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7b66bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5988 images belonging to 109 classes.\n",
      "Found 1496 images belonging to 109 classes.\n",
      "Epoch 1/10\n",
      "188/188 [==============================] - 30515s 163s/step - loss: 4.2633 - accuracy: 0.0762 - val_loss: 3.7153 - val_accuracy: 0.1491\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 4434s 24s/step - loss: 3.3180 - accuracy: 0.2283 - val_loss: 3.0991 - val_accuracy: 0.2487\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 6330s 34s/step - loss: 2.7737 - accuracy: 0.3180 - val_loss: 2.7248 - val_accuracy: 0.3329\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 4625s 25s/step - loss: 2.4320 - accuracy: 0.3975 - val_loss: 2.5002 - val_accuracy: 0.3723\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 14466s 77s/step - loss: 2.1838 - accuracy: 0.4442 - val_loss: 2.3522 - val_accuracy: 0.4091\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 1306s 7s/step - loss: 2.0331 - accuracy: 0.4749 - val_loss: 2.2662 - val_accuracy: 0.4144\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 3664s 20s/step - loss: 1.8846 - accuracy: 0.5037 - val_loss: 2.1899 - val_accuracy: 0.4225\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 1633s 9s/step - loss: 1.7619 - accuracy: 0.5362 - val_loss: 2.1256 - val_accuracy: 0.4639\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 9497s 51s/step - loss: 1.6751 - accuracy: 0.5523 - val_loss: 2.0508 - val_accuracy: 0.4666\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 1675s 9s/step - loss: 1.5853 - accuracy: 0.5783 - val_loss: 2.0381 - val_accuracy: 0.4739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # Set aside 20% for validation\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'animal_dataset/animals/combined_file',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'animal_dataset/animals/combined_file',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_generator, validation_data=validation_generator, epochs=10)\n",
    "\n",
    "model.save('species_classifier.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1ee6395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5988 images belonging to 109 classes.\n",
      "Found 1496 images belonging to 109 classes.\n",
      "Epoch 1/20\n",
      "188/188 [==============================] - 1262s 7s/step - loss: 4.2574 - accuracy: 0.0830 - val_loss: 3.7388 - val_accuracy: 0.1437\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 1038s 6s/step - loss: 3.2849 - accuracy: 0.2311 - val_loss: 3.1059 - val_accuracy: 0.2607\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 1024s 5s/step - loss: 2.7490 - accuracy: 0.3315 - val_loss: 2.7462 - val_accuracy: 0.3275\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 1279s 7s/step - loss: 2.3935 - accuracy: 0.4000 - val_loss: 2.5012 - val_accuracy: 0.3877\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 1281s 7s/step - loss: 2.1861 - accuracy: 0.4456 - val_loss: 2.3482 - val_accuracy: 0.4064\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 1283s 7s/step - loss: 2.0043 - accuracy: 0.4828 - val_loss: 2.2429 - val_accuracy: 0.4225\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 1249s 7s/step - loss: 1.8623 - accuracy: 0.5184 - val_loss: 2.2099 - val_accuracy: 0.4251\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 1010s 5s/step - loss: 1.7518 - accuracy: 0.5391 - val_loss: 2.1436 - val_accuracy: 0.4459\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 975s 5s/step - loss: 1.6517 - accuracy: 0.5610 - val_loss: 2.0538 - val_accuracy: 0.4679\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 983s 5s/step - loss: 1.5624 - accuracy: 0.5798 - val_loss: 1.9816 - val_accuracy: 0.4873\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 981s 5s/step - loss: 1.4816 - accuracy: 0.5990 - val_loss: 2.0324 - val_accuracy: 0.4733\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 993s 5s/step - loss: 1.4021 - accuracy: 0.6234 - val_loss: 1.9455 - val_accuracy: 0.4953\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 1278s 7s/step - loss: 1.3436 - accuracy: 0.6401 - val_loss: 1.8980 - val_accuracy: 0.5140\n",
      "Epoch 14/20\n",
      "188/188 [==============================] - 1300s 7s/step - loss: 1.2814 - accuracy: 0.6568 - val_loss: 1.8297 - val_accuracy: 0.5107\n",
      "Epoch 15/20\n",
      "188/188 [==============================] - 1319s 7s/step - loss: 1.2222 - accuracy: 0.6688 - val_loss: 1.8937 - val_accuracy: 0.5020\n",
      "Epoch 16/20\n",
      "188/188 [==============================] - 1349s 7s/step - loss: 1.1781 - accuracy: 0.6834 - val_loss: 1.8198 - val_accuracy: 0.5174\n",
      "Epoch 17/20\n",
      "188/188 [==============================] - 1432s 8s/step - loss: 1.1401 - accuracy: 0.6877 - val_loss: 1.8359 - val_accuracy: 0.5247\n",
      "Epoch 18/20\n",
      "188/188 [==============================] - 1415s 8s/step - loss: 1.0900 - accuracy: 0.6947 - val_loss: 1.8022 - val_accuracy: 0.5368\n",
      "Epoch 19/20\n",
      "188/188 [==============================] - 32910s 176s/step - loss: 1.0341 - accuracy: 0.7156 - val_loss: 1.8200 - val_accuracy: 0.5294\n",
      "Epoch 20/20\n",
      "188/188 [==============================] - 1418s 8s/step - loss: 0.9951 - accuracy: 0.7273 - val_loss: 1.8094 - val_accuracy: 0.5535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2 \n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'animal_dataset/animals/combined_file',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'animal_dataset/animals/combined_file',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_generator, validation_data=validation_generator, epochs=20)\n",
    "\n",
    "model.save('species_classifier1.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be6bffe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "188/188 [==============================] - 1384s 7s/step - loss: 0.9725 - accuracy: 0.7244 - val_loss: 1.7853 - val_accuracy: 0.5381\n",
      "Epoch 22/30\n",
      "188/188 [==============================] - 1386s 7s/step - loss: 0.9232 - accuracy: 0.7437 - val_loss: 1.7967 - val_accuracy: 0.5247\n",
      "Epoch 23/30\n",
      "188/188 [==============================] - 2763s 15s/step - loss: 0.8847 - accuracy: 0.7573 - val_loss: 1.7141 - val_accuracy: 0.5608\n",
      "Epoch 24/30\n",
      "188/188 [==============================] - 1022s 5s/step - loss: 0.8477 - accuracy: 0.7632 - val_loss: 1.8200 - val_accuracy: 0.5361\n",
      "Epoch 25/30\n",
      "188/188 [==============================] - 987s 5s/step - loss: 0.8222 - accuracy: 0.7709 - val_loss: 1.7358 - val_accuracy: 0.5615\n",
      "Epoch 26/30\n",
      "188/188 [==============================] - 984s 5s/step - loss: 0.7899 - accuracy: 0.7851 - val_loss: 1.7178 - val_accuracy: 0.5615\n",
      "Epoch 27/30\n",
      "188/188 [==============================] - 972s 5s/step - loss: 0.7633 - accuracy: 0.7867 - val_loss: 1.7553 - val_accuracy: 0.5675\n",
      "Epoch 28/30\n",
      "188/188 [==============================] - 973s 5s/step - loss: 0.7381 - accuracy: 0.7924 - val_loss: 1.7847 - val_accuracy: 0.5702\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint('species_classifier_best.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min')\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=30,\n",
    "    initial_epoch=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[checkpoint, early_stopping]\n",
    ")\n",
    "\n",
    "model.save('species_classifier_extended_30_epochs_final.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "155094fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "188/188 [==============================] - 1060s 6s/step - loss: 0.6967 - accuracy: 0.8046 - val_loss: 1.7534 - val_accuracy: 0.5655\n",
      "Epoch 30/30\n",
      "188/188 [==============================] - 1102s 6s/step - loss: 0.6834 - accuracy: 0.8113 - val_loss: 1.7305 - val_accuracy: 0.5742\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint('species_classifier_best.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min')\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=30,\n",
    "    initial_epoch=28,\n",
    "    batch_size=32,\n",
    "    callbacks=[checkpoint, early_stopping]\n",
    ")\n",
    "\n",
    "model.save('species_classifier_final.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bc7cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
